---
title: "这就是 ChatGPT"
author: "吴诗涛"
date: "2025-02-02"
slug: "what-is-chatgpt-doing-and-why-does-it-work"
---

- 斯蒂芬·沃尔弗拉姆  《这就是 ChatGPT》
- https://book.douban.com/subject/36449803/
- [书摘卡片](http://49.234.56.82:5244/drive/Card/%E8%BF%99%E5%B0%B1%E6%98%AF%20ChatGPT)

# ChatGPT 在做什么？它为何能做到这些？

- ChatGPT 从根本上始终要做的是，针对它得到的任何文本产生“合理的延续”。这里所说的“合理”是指，“人们在看到诸如数十亿个网页上的内容后，可能期待别人会这样写”。

- 当 ChatGPT 做一些事情，比如写一篇文章时，它实质上只是在一遍又一遍地询问“根据目前的文本，下一个词应该是什么”，并且每次都添加一个词。正如我将要解释的那样，更准确地说，它是每次都添加一个“标记”（token），而标记可能只是词的一部分。这就是它有时可以“造词”的原因。

- 必须理解，从来没有“无模型的模型”。你使用的任何模型都有某种特定的基本结构，以及用于拟合数据的一定数量的“旋钮”（也就是可以设置的参数）。ChatGPT 使用了许多这样的“旋钮”实际上有 1750 亿个。

- 如果函数给出的结果总是与人类的意见相符，那么我们就有了一个“好模型”。一个重大的科学事实是，对于图像识别这样的任务，我们现在基本上已经知道如何构建不错的函数了。

- 实际上，“深度学习”在 2012 年左右的重大突破与如下发现有关：与权重相对较少时相比，在涉及许多权重时，进行最小化（至少近似）可能会更容易。

  换句话说，有时候用神经网络解决复杂问题比解决简单问题更容易——这似乎有些违反直觉。大致原因在于，当有很多“权重变量”时，高维空间中有“很多不同的方向”可以引导我们到达最小值；而当变量较少时，很容易陷入局部最小值的“山湖”，无法找到“出去的方向”。

- 在越来越多的情况下，人们并不从头开始训练网络：一个新的网络可以直接包含另一个已经训练过的网络，或者至少可以使用该网络为自己生成更多的训练样例。

- 能力和可训练性之间存在着一个终极权衡：你越想让一个系统“真正利用”其计算能力，它就越会表现出计算不可约性从而越不容易被训练；而它在本质上越易于训练，就越不能进行复杂的计算。

- 如果有一个足够大的神经网络，那么你可能能够做到人类可以轻易做到的任何事情。但是你无法捕捉自然界一般而言可以做到的事情，或者我们用自然界塑造的工具可以做到的事情。而正是这些工具的使用，无论是实用性的还是概念性的，近几个世纪以来使我们超越了“纯粹的无辅助的人类思维”的界限，为人类获取了物理宇宙和计算宇宙之外的很多东西。

- 那么，ChatGPT 是如何在语言方面获得如此巨大成功的呢？我认为基本答案是，语言在根本上比它看起来更简单。这意味着，即使是具有简单的神经网络结构的 ChatGPT，也能够成功地捕捉人类语言的“本质”和背后的思维方式。此外，在训练过程中，ChatGPT 已经通过某种方式“隐含地发现”了使这一切成为可能的语言（和思维）规律。

  我认为，ChatGPT 的成功为一个基础而重要的科学事实向我们提供了证据：它表明我们仍然可以期待能够发现重大的新“语言法则”实际上是“思维法则”。在 ChatGPT 中，由于它是一个神经网络，这些法则最多只是隐含的。但是，如果我们能够通过某种方式使这些法则变得明确，那么就有可能以更直接、更高效和更透明的方式做出 ChatGPT 所做的那些事情。

# 利用 Wolfram|Alpha 为 ChatGPT 赋予计算知识超能力

- 虽然 ChatGPT 在自动化执行主要的类人任务方面取得了显著的成就，但并非所有有用的任务都是如此“类人”的。一些任务是更加形式化、结构化的。实际上，我们的文明在过去几个世纪中取得的一项伟大成就就是建立了数学、精密科学——最重要的是计算——的范式，并且创建了一座能力高塔，与纯粹的类人思维所能达到的高度完全不同。

- 虽然 Wolfram|Alpha 和 ChatGPT 所做的事情完全不同，做事的方式也完全不同，但它们有一个公共接口：自然语言。这意味着 ChatGPT 可以像人类一样与 Wolfram|Alpha “交谈”，而 Wolfram|Alpha 会将它从 ChatGPT 获得的自然语言转换为精确的符号计算语言，从而应用其计算知识能力。

- 结果从来不是“完美”的。也许有的东西能够在 95% 的时间内运作良好。但是不论怎样努力，它的表现在剩下的 5% 时间内仍然难以捉摸。对于某些情况来说，这可能被视为失败。但关键在于在各种重要的用例中，95% 往往就“足够好了”。原因也许是输出是一种没有“正确答案”的东西，也许是人们只是在试图挖掘一些可能性供人类（或系统算法）选择或改进。

- 在许多方面，可以说 ChatGPT 从未“真正理解”过事物，它只“知道如何产生有用的东西”。但是 Wolfram|Alpha 则完全不同。因为一旦 Wolfram|Alpha 将某些东西转换为 Wolfram 语言，我们就拥有了它们完整、精确、形式化的表示，可以用来可靠地计算事物。不用说，有很多“人类感兴趣”的事物并没有形式化的计算表示——尽管我们仍然可以用自然语言谈论它们，但是可能不够准确。对于这些事物，ChatGPT 只能靠自己，而且能凭借自己的能力做得非常出色。

- Wolfram 语言的总体概念就是对我们人类的所思所想进行计算上的表示和处理。普通的编程语言旨在确切地告诉计算机要做什么，而作为一门全面的计算语言，Wolfram 语言涉及的范围远远超出了这一点。实际上，它旨在成为一门既能让人类也能让计算机“用计算思维思考”的语言。

